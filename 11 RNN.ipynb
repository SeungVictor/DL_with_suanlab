{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 순환 신경망\n",
    "\n",
    "- Recurrent Neural Network\n",
    "\n",
    "- 시계열 데이터와 같이 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eT8Pk_xTF75M",
    "tags": []
   },
   "source": [
    "# 자연어 처리(Natural Language Processing, NLP)\n",
    "\n",
    "- 한국어, 영어 등 우리가 평소에 쓰는 언어\n",
    "\n",
    "- 사람의 말을 컴퓨터가 이해하도록 수행하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoWecPwRF8sw"
   },
   "source": [
    "## 신경망에서의 단어 처리 (단어 임베딩, Word Embedding)\n",
    "- 단어를 있는 그대로 처리하지 않고 고정 길이의 벡터로 표현 (원-핫 인코딩)\n",
    "\n",
    "- 단어 하나에 인덱스 정수를 할당하는 Bag of Words 방법\n",
    "\n",
    "- 예시)  \n",
    "  \"you\", \"are\", \"not\", \"a\", \"smart\", \"student\"\n",
    "\n",
    "  - \"you\"     : 0\n",
    "  - \"are\"     : 1\n",
    "  - \"not\"     : 2\n",
    "  - \"a\"       : 3\n",
    "  - \"smart\"   : 4\n",
    "  - \"student\" : 5\n",
    "\n",
    "        \"You are a smart student.\"  \n",
    "    ---> [1, 1, 0, 1, 1, 1]\n",
    "\n",
    "  <br>\n",
    "  \n",
    "  <img src=\"https://miro.medium.com/max/1348/1*YEJf9BQQh0ma1ECs6x_7yQ.png\" width=\"600\">\n",
    "\n",
    "  <sub>출처: https://medium.com/@athif.shaffy/one-hot-encoding-of-text-b69124bef0a7</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wga06Nz-F-qI"
   },
   "source": [
    "## 신경망에서의 단어처리 구조\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1000/1*1O5gLhOg25HviI8bwZxV4g.png\" width=\"600\">\n",
    "\n",
    "<sub>출처: https://mc.ai/deep-nlp-word-vectors-with-word2vec/</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4Yk95bFTU27"
   },
   "source": [
    "## CBOW (Continuous Bag of Words) Embedding\n",
    "- 복수 단어 문맥(multi-word context)에 대한 문제  \n",
    "  즉, 여러개의 단어를 나열한 뒤 이와 관련된 단어를 추정하는 문제\n",
    "\n",
    "- 예를 들어,  \n",
    "      Betty bought a bit of better butter.\n",
    "\n",
    "  위 예시에서 (Betty, a bit, butter)라는 문맥이 주어지면 bought를 예측하는 구조\n",
    "\n",
    "  <br>\n",
    "\n",
    "  <img src=\"https://miro.medium.com/max/604/1*DfuBd49nCtT99h328iXL2Q.png\" width=\"300\">\n",
    "\n",
    "  <sub>출처: https://medium.com/@srishtee.kriti/mathematics-behind-continuous-bag-of-words-cbow-model-1e54cc2ecd88</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxa8iUpaTVsB"
   },
   "source": [
    "## Skip-Gram Embedding\n",
    "- CBOW 방식과 반대\n",
    "\n",
    "- 특정한 단어로부터 문맥이 될 수 있는 단어를 예측\n",
    "\n",
    "- 보통 입력 단어 주변의  $k$ 개 단어를 문맥으로 보고 예측 모형을 만드는데 이  $k$ 값을 window size 라고 한다.\n",
    "\n",
    "- 예시) window size = 2 라면,  \n",
    "      Betty -> bought, butter  \n",
    "      bought -> butter, Betty  \n",
    "      a -> bit, of  \n",
    "\n",
    "  <br>\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/publication/322905432/figure/fig1/AS:614314310373461@1523475353979/The-architecture-of-Skip-gram-model-20.png\" width=\"300\">\n",
    "\n",
    "  <sub>출처: https://www.researchgate.net/figure/The-architecture-of-Skip-gram-model-20_fig1_322905432</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgQhTm1BTYt1"
   },
   "source": [
    "## Word2Vec\n",
    "- CBOW, Skip_Gram 방식의 단어 임베딩을 구현.  \n",
    "  구글의 Mikolov 개발\n",
    "\n",
    "- subsampling, negative sampling 등의 기법 추가하여 학습 속도 향상\n",
    "\n",
    "  <img src=\"https://mbenhaddou.com/wp-content/uploads/2019/12/img_4.png\">\n",
    "\n",
    "  <sub>출처: http://mbenhaddou.com/2019/12/14/word2vec-concepts-from-scratch/</sub>\n",
    "\n",
    "  <br>\n",
    "\n",
    "  <img src=\"https://miro.medium.com/max/2456/1*gcC7b_v7OKWutYN1NAHyMQ.png\" width=\"600\">\n",
    "\n",
    "  <sub>출처: https://towardsdatascience.com/word-embeddings-for-nlp-5b72991e01d4</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26OlAvwKTbYz"
   },
   "source": [
    "## Word2Vec 예제\n",
    "\n",
    "- 출처: https://datascienceschool.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1ABlKJAcTcw4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/spark/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/spark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FrIAzCzwTc_l"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "sentences = [list(s) for s in movie_reviews.sents()]\n",
    "#moviereviews에서 sentences를 모두뽑아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PB7kBcQETdPv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YO2hFz3iTda7"
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AXJvPZZyTdV9"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hqQq37bITdIw"
   },
   "outputs": [],
   "source": [
    "#model.init_sims(replace=True)#모델의 초기화 4.0버전부터는 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3hNQ_O18TdGs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('fruit', 'apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L95sLAsbTc4R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8328698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('he', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1-U_PxqMTc20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16611011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('fruit', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hpIdkITrTwHu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cart', 0.9393925070762634),\n",
       " ('flock', 0.9378735423088074),\n",
       " ('crossing', 0.9343571066856384),\n",
       " ('kentucky', 0.9330583214759827),\n",
       " ('onegin', 0.9327878355979919),\n",
       " ('cloud', 0.929882287979126),\n",
       " ('capital', 0.9291256070137024),\n",
       " ('fury', 0.928852379322052),\n",
       " ('cocaine', 0.9283703565597534),\n",
       " ('engine', 0.9280326962471008)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fruit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n5PYKGZgTwSB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('floor', 0.7987210154533386)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['ship', 'sky'], negative='sea', topn=1)\n",
    "#관계를 통한 질의 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# 고차원을 저차원으로 변환\n",
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_vocab = model.wv.key_to_index\n",
    "# review_vocab\n",
    "# review_similarity = model[review_vocab]\n",
    "# review_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# similarity = tsne.fit_transform(review_similarity)\n",
    "# review_df = pd.DataFrame(similarity, index=review_vocab, columns=['x', 'y'])\n",
    "# review_df = review_df[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('seaborn-white')\n",
    "# fig = plt.figure(figsize=(14,14))\n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "# ax.scatter(review_1000['x'], review_1000['y'])\n",
    "# for word, pos in review_1000.itterrows():\n",
    "#     ax.annotate(word,pos)\n",
    "# ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFyGsWqpT4tP",
    "tags": []
   },
   "source": [
    "### 네이버 영화 감상 코퍼스를 사용한 한국어 단어 임베딩\n",
    "- 한국어 임베딩은 \"konlpy\" 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "plt.rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K5awuhIsTwUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-26 07:14:37--  http://=/\n",
      "= (=) 해석 중... 실패: nodename nor servname provided, or not known.\n",
      "wget: `=' 호스트 주소를 해석할 수 없습니다\n",
      "--2021-10-26 07:14:37--  http://nc/\n",
      "nc (nc) 해석 중... 실패: nodename nor servname provided, or not known.\n",
      "wget: `nc' 호스트 주소를 해석할 수 없습니다\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2021-10-26 07:14:37--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) 해석 중... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "다음으로 연결 중: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 14628807 (14M) [text/plain]\n",
      "저장 위치: `ratings_train.txt.2'\n",
      "\n",
      "ratings_train.txt.2 100%[===================>]  13.95M  5.81MB/s    /  2.4s    \n",
      "\n",
      "2021-10-26 07:14:41 (5.81 MB/s) - `ratings_train.txt.2' 저장함 [14628807/14628807]\n",
      "\n",
      "완료 --2021-10-26 07:14:41--\n",
      "총 wall 클록 시간: 4.1s\n",
      "다운로드: 1 파일, 2.4s중 14M (5.81 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget = nc http://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MV16Az5MeOxr"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def read_data(filename):\n",
    "    with codecs.open(filename, encoding='utf-8', mode='r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]#head제외\n",
    "    return data\n",
    "\n",
    "train_data = read_data('ratings_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DbIDwP6iTwZP"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #형태소분석기\n",
    "tagger = Okt()\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "train_docs = [row[1] for row in train_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [tokenize(d) for d in train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "C60vas6reXb3"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kU9ab9fhTwhi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/xfclsffs46x_pr2y70z2qfsm0000gn/T/ipykernel_5783/1484743238.py:2: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PtGSMyX4Twf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73263925"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(*tokenize(u'배우 여배우'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nUvMyPKUTwMo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25139028"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(*tokenize(u'배우 남자'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aMscjdX9Tcr1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('여배우/Noun', 0.8048993349075317),\n",
       " ('여자/Noun', 0.7829231023788452),\n",
       " ('연기자/Noun', 0.7624119520187378),\n",
       " ('캐릭터/Noun', 0.7158713340759277),\n",
       " ('조연/Noun', 0.6987995505332947),\n",
       " ('가수/Noun', 0.6814426183700562),\n",
       " ('출연자/Noun', 0.675133466720581),\n",
       " ('남자배우/Noun', 0.6636179089546204),\n",
       " ('배역/Noun', 0.6582420468330383),\n",
       " ('게스트/Noun', 0.6486083269119263)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(tokenize(u'배우 남자'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bXa0zrC5UNZT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('총/Noun', 0.8185046911239624),\n",
       " ('때리다/Verb', 0.7632945775985718),\n",
       " ('죽이다/Verb', 0.7538633942604065),\n",
       " ('도망가다/Verb', 0.7489215135574341),\n",
       " ('잡다/Verb', 0.7291643023490906),\n",
       " ('붙다/Verb', 0.725366473197937),\n",
       " ('자르다/Verb', 0.7196257710456848),\n",
       " ('불/Noun', 0.7080297470092773),\n",
       " ('입다/Verb', 0.7039275169372559),\n",
       " ('총알/Noun', 0.6907637119293213)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(tokenize(u'쏘다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_4_3j4YdUNQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('여자/Noun', 0.8055566549301147),\n",
      " ('여자애/Noun', 0.7284619808197021),\n",
      " ('고양이/Noun', 0.6913424730300903)]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.utils import pprint\n",
    "\n",
    "pprint(model.wv.most_similar(positive=tokenize(u'남자 여배우'), negative=tokenize(u'배우'), topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_vocab = model.wv.key_to_index\n",
    "# review_vocab\n",
    "# review_similarity = model[review_vocab]\n",
    "# review_similarity\n",
    "# from sklearn.manifold import TSNE\n",
    "# # 고차원을 저차원으로 변환\n",
    "# tsne = TSNE(n_components=2)\n",
    "# similarity = tsne.fit_transform(review_similarity)\n",
    "# review_df = pd.DataFrame(similarity, index=review_vocab, columns=['x', 'y'])\n",
    "# review_df = review_df[0:1000]\n",
    "\n",
    "# fig = plt.figure(figsize=(14,14))\n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "# ax.scatter(review_1000['x'], review_1000['y'])\n",
    "# for word, pos in review_1000.itterrows():\n",
    "#     ax.annotate(word,pos)\n",
    "# ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jacLnynuqUXZ"
   },
   "source": [
    "# 순환 신경망 (Recurrent Neural Network, RNN)\n",
    "\n",
    "- **순서가 있는 데이터**를 입력으로 받음\n",
    "\n",
    "- 변화하는 입력에 대한 출력을 얻음\n",
    "\n",
    "- 시계열(날씨, 주가 등), 자연어와 같이 **시간의 흐름에 따라 변화하고, 그 변화가 의미를 갖는 데이터** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P0gpo4gqWUz"
   },
   "source": [
    "## Feed Forward Network vs Recurrent Network\n",
    "\n",
    "- Feed Forward Net (앞먹임 구조)\n",
    "  - 일반적인 구조의 신경망\n",
    "\n",
    "  - 입력 → 은닉 → 출력층 으로 이어지는 단방향 구조\n",
    "\n",
    "  - 이전 스텝의 출력의 영향을 받지 않음\n",
    "\n",
    "- Recurrent Net (되먹임 구조)\n",
    "  - 이전 층(Layer), 또는 스텝의 출력이 다시 입력으로 연결되는 신경망 구조\n",
    "\n",
    "  - 각 스텝마다 이전 상태를 기억 시스템(Memory System)  \n",
    "\n",
    "  - 현재 상태가 이전 상태에 종속\n",
    "\n",
    "  <br>\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/profile/Engin_Pekel/publication/315111480/figure/fig1/AS:472548166115333@1489675670530/Feed-forward-and-recurrent-ANN-architecture.png\">\n",
    "\n",
    "  <sub>출처: https://www.researchgate.net/figure/Feed-forward-and-recurrent-ANN-architecture_fig1_315111480</sub>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h5HFH0BqYho"
   },
   "source": [
    "## 순환 신경망 구조\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"700\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- 입력 $x_t$에서 $t$는 시각을 뜻함\n",
    "\n",
    "- $X_0$에 대한 출력 $Y_0$이 다음 레이어에 전달\n",
    "\n",
    "- 각각의 입력에 대해 출력은 해당 레이어대로 출력값을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kowOGfSLqbSn"
   },
   "source": [
    "## 순환 신경망의 다양한 구조\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781789346640/graphics/2d4a64ef-9cf9-4b4a-9049-cb9de7a07f89.png\">\n",
    "  \n",
    "  <sub>출처: https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789346640/11/ch11lvl1sec80/introduction</sub>\n",
    "\n",
    "- one to one\n",
    "  - RNN\n",
    "\n",
    "- one to many\n",
    "  - Image Captioning \n",
    "\n",
    "  - 이미지에 대한 설명 생성\n",
    "\n",
    "- many to one\n",
    "  - Sentiment Classification\n",
    "\n",
    "  - 문장의 긍정/부정을 판단하는 감정 분석\n",
    "\n",
    "- many to many\n",
    "  - Machine Translation\n",
    "\n",
    "  - 하나의 언어를 다른 언어로 번역하는 기계 번역\n",
    "\n",
    "- many to many\n",
    "  - Video Classification(Frame Level)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiIA4Ue7-G5B"
   },
   "source": [
    "## 두 가지 정보(현재 입력, 이전 시각의 출력)을 처리하는 수식\n",
    "$\\qquad h_t = tanh ( \\ h_{t-1} W_h \\ + \\ x_t W_x + b) $\n",
    "\n",
    "- $W_x$ : 입력 $x$를 출력 $h$로 변환하기 위한 가중치\n",
    "\n",
    "- $W_h$ : 다음 시각의 출력으로 변환하기 위한 가중치\n",
    "\n",
    "- $h$는 '상태'를 기억\n",
    "\n",
    "- $h_t \\ $를 은닉 상태(hidden state) 또는 은닉 상태 벡터(hidden state vector)라고도 불림\n",
    "\n",
    "  <sub>출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs/</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNUu9LzO-KcF"
   },
   "source": [
    "## BPTT(BackPropagation Through Time)\n",
    "\n",
    "- 시간 방향으로 펼친 신경망의 오차역전파\n",
    "\n",
    "- 시계열 데이터의 시간 크기가 커지면 역전파 시 불안정해짐\n",
    "\n",
    "- 기울기 소실 문제 발생\n",
    "\n",
    "  <img src=\"https://iamtrask.github.io/img/backprop_through_time.gif\" width=\"700\">\n",
    "\n",
    "  <sub>출처: https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIJmsDgw-WWS"
   },
   "source": [
    "## Truncated BPTT\n",
    "\n",
    "- 큰 시계열 데이터를 다룰 때 사용하는 오차역전파법\n",
    "\n",
    "- 신경망을 **적당한 길이로 끊는다.**\n",
    "  - <u>역전파에 연결만! 순전파의 연결은 끊어지지 않는다.</u>\n",
    "\n",
    "- 학습 시, 입력이 **순서대로 연결**되어 입력해야 함\n",
    "\n",
    "  <img src=\"https://r2rt.com/static/images/RNN_true_truncated_backprop.png\">\n",
    "\n",
    "  <sub>출처: https://r2rt.com/styles-of-truncated-backpropagation.html</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dpRw1XV-Y9n"
   },
   "source": [
    "## RNN 구현\n",
    "\n",
    "- 형상 주의!\n",
    "\n",
    "## $\\qquad \\ h_{t-1} W_h \\ + \\ x_t W_x = h_t$\n",
    "\n",
    "- $h_{t-1}$ : $N \\times H$\n",
    "\n",
    "- $W_{h}$ : $H \\times H$\n",
    "\n",
    "- $x_{t}$ : $N \\times D$\n",
    "\n",
    "- $W_{x}$ : $D \\times H$\n",
    "\n",
    "- $h_t$ : $N \\times H$\n",
    "\n",
    "- $D$ : 입력 벡터의 차원 수\n",
    "\n",
    "- $H$ : 은닉 상태 벡터의 차원 수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Arjp1LQbuVc5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class RNN:\n",
    "    def __init__(self, W_x, W_h, bias):\n",
    "        self.params = [W_x, W_h, bias]\n",
    "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np_zeros_like(b)]\n",
    "        \n",
    "        self.temp = None\n",
    "         \n",
    "    def forward(self, input_data, h_prev):\n",
    "        W_x, W_h, bias = self.params\n",
    "        t = np.matmul(h_prev, W_h)+ np.matmul(input_data, W_x) + bias\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.temp = (input_data, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        W_x, W_h, bias = self.params\n",
    "        input_data, h_prev, h_next = self.temp\n",
    "        \n",
    "        dt = dh_next * (1 - h_next**2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, W_h.T)\n",
    "        dWx = np.matmul(input_data.T, dt)\n",
    "        dx = np.matmul(dt, W_x.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRZ47KbtFj8O"
   },
   "source": [
    "## Time RNN Layer\n",
    "- RNN 계층의 은닉상태 $h$를 가지고 있음\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "VQhOF1RHFhVH"
   },
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, W_x, W_h, bias, stateful=False):\n",
    "        self.params =[W_x, W_h, bias]\n",
    "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np.zeros_like(bias)]\n",
    "        self.layers = None\n",
    "        self.hidden_state = None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, hidden_state):\n",
    "        self.hidden_state = hidden_state\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.hidden_state = None\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        W_x, W_h, bias = self.params\n",
    "        N, T, D = input_data.shape\n",
    "        D, H = W_x.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        output = np.empty((N, T, H), dtype = 'f')\n",
    "        \n",
    "        if not self.stateful or self.hidden_state is None:\n",
    "            self.hidden_state = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.hidden_state = layer.forward(input_data[:, t, :], self.h)\n",
    "            output[:, t, :] = self.hidden_state\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def backward(self, doutput):\n",
    "        W_x, W_h, bias = self.params\n",
    "        N, T, H = doutput.shape\n",
    "        D, H = W_x.shape\n",
    "        dinput = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        \n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(doutput[:, t, :] + dh)\n",
    "            dinput[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "            \n",
    "        self.dh = dh\n",
    "        \n",
    "        return dinput\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzFqvo2aFpMb"
   },
   "source": [
    "# LSTM (Long Shot-Term Memory)\n",
    "\n",
    "- RNN은 장기 기억을 제대로 처리 못함\n",
    "\n",
    "- RNN은 기울기 소실 또는 기울기 폭발을 발생\n",
    "\n",
    "- 위를 해결하기 위해 LSTM 방법 등장\n",
    "\n",
    "  <img src=\"https://www.researchgate.net/publication/324600237/figure/fig3/AS:616974623178753@1524109621725/Long-Short-term-Memory-Neural-Network.png\" width=\"600\">\n",
    "\n",
    "<sub>출처: https://www.researchgate.net/figure/Long-Short-term-Memory-Neural-Network_fig3_324600237</sub>\n",
    "\n",
    "### $\\qquad f = \\sigma (x_t W^{(f)}_x + h_{t-1} W^{(f)}_h + b^{(f)}) \\\\ \n",
    "\\qquad g = tanh(x_t W^{(g)}_x + h_{t-1} W^{(g)}_h + b^{(g)}) \\\\\n",
    "\\qquad i = \\sigma(x_t W^{(i)}_x + h_{t-1} W^{(i)}_h + b^{(i)}) \\\\\n",
    "\\qquad o = \\sigma(x_t W^{(o)}_x + h_{t-1} W^{(o)}_h + b^{(o)})$\n",
    "\n",
    "\n",
    "### $\\qquad c_t = f \\odot c_{t-1} + g \\odot i \\\\\n",
    "\\qquad h_t = o \\odot tanh(c_t)\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii53247RFu9N"
   },
   "source": [
    "## forget gate (망각 게이트)\n",
    "- 불필요한 정보를 잊는 게이트\n",
    "\n",
    "-  $h_{t−1}$ 과 $x_t$ 를 받아 시그모이드를 취해준 값이 forget gate의 출력값\n",
    "\n",
    "- 시그모이드 함수를 통과하기 때문에 그 값이 0이라면 이전 상태의 정보는 잊고, 1이라면 이전 상태의 정보를 온전히 기억\n",
    "\n",
    "  <img src=\"https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-25-638.jpg?cb=1485365064\" width=\"600\">\n",
    "\n",
    "  <sub>출처: https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXhr1CGwF1S2"
   },
   "source": [
    "## input gate (입력 게이트)\n",
    "- 현재 정보를 기억하기’ 위한 게이트\n",
    "\n",
    "- $h_{t−1}$ 과 $x_t$를 받아 $Sigmoid$ -> $tanh$ 를 통과한 다음,  \n",
    "  Hadamard product 연산을 한 값을 출력\n",
    "  \n",
    "  <br>\n",
    "\n",
    "  <img src=\"https://image.slidesharecdn.com/dlmmdcud2l08recurrentneuralnetworks-170429103823/95/recurrent-neural-networks-d2l8-insightdcu-machine-learning-workshop-2017-28-638.jpg?cb=1493462658\" width=\"600\">\n",
    "\n",
    "  <sub>출처: https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyrTIpZhFxyR"
   },
   "source": [
    "## output gate (출력 게이트)\n",
    "\n",
    "- 은닉 상태 $h_t$의 출력을 담당하는 게이트\n",
    "\n",
    "- 입력 $x_t$와 이전 상태 $h_{t-1}$로부터 게이트의 열림 상태가 결정됨\n",
    "\n",
    "  <img src=\"https://image.slidesharecdn.com/dlcvd2l6recurrentneuralnetworks-160802094750/95/deep-learning-for-computer-vision-recurrent-neural-networks-upc-2016-30-638.jpg?cb=1470131837\" width=\"600\">\n",
    "\n",
    "<sub>출처: https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-recurrent-neural-networks-upc-2016</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJVkn0D6F3Yz"
   },
   "source": [
    "## LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gjrZLUk8Fpba"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, W_x, W_h, bias):\n",
    "        self.params = [W_x, W_h, bias]\n",
    "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np_zeros_like(bias)]\n",
    "        self.temp = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        W_x, W_h, bias = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, W_x) + np.dot(h_prev, W_h) + bias\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = i * np.tanh(c_next)\n",
    "        \n",
    "        self.temp = (x, h_prev, c_prev, i, f, h, o, c_next)\n",
    "        return h_next, c_next\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        W_x, W_h, bias = self.params\n",
    "        x, h_prev, c_prev, i, f, h, o, c_next = self.temp\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        \n",
    "        ds = dc_next + (dh_next * c) * (1 - tanh_c_next**2)\n",
    "        dc_prev = ds * f\n",
    "        \n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * id\n",
    "        \n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 -g**2)\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        dx = np.dot(dA, W_x.T)\n",
    "        dh_prev = np.dot(dA, W_h.T)\n",
    "        \n",
    "        return dx, dh_prev, dc_prev\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc0wuvArGHgD"
   },
   "source": [
    "# GRU (Gated Recurrent Unit)\n",
    "- LSTM을 더 단순하게 만든 구조\n",
    "\n",
    "- 기억 셀은 없고, 시간방향으로 전파하는 것은 은닉 상태만 있음\n",
    "\n",
    "- reset gate\n",
    "  - 과거의 은닉 상태를 얼마나 무시할지 결정\n",
    "\n",
    "  - $r$ 값이 결정\n",
    "\n",
    "- update gate\n",
    "  -  은닉 상태를 갱신하는 게이트  \n",
    "\n",
    "  - LSTM의 forget, input gate 역할을 동시에 함\n",
    "  \n",
    "  <img src=\"https://miro.medium.com/max/1400/1*jhi5uOm9PvZfmxvfaCektw.png\" width=\"500\">\n",
    "\n",
    "<sub>출처: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21</sub>\n",
    "\n",
    "  ### $\\qquad z = \\sigma (x_t W^{(z)}_x + h_{t-1} W^{(z)}_h + b^{(z)} \\\\ \n",
    "  \\qquad r = \\sigma (x_t W^{(r)}_x + h_{t-1} W^{(r)}_h + b^{(r)}) \\\\\n",
    "  \\qquad \\tilde{i} = tanh (x_t W^{(i)}_x + (r \\odot h_{t-1}) W^{(i)}_h + b ) \\\\\n",
    "  \\qquad h_t = (1 - z) \\odot h_{t-1} + z \\odot \\tilde{h}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n96GGOgsGKhE"
   },
   "source": [
    "# (참고) RNN vs LSTM vs GRU\n",
    "\n",
    "<img src=\"https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1849/http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU.png\">\n",
    "\n",
    "<sub>출처: http://dprogrammer.org/rnn-lstm-gru</sub>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of _11 RNN.ipynb",
   "provenance": [
    {
     "file_id": "1OEOdA2JEH2V9zrgqFYywvwxUxdcZGyg5",
     "timestamp": 1628856943375
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
